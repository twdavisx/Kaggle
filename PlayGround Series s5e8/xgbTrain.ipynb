{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"},{"sourceId":9293783,"sourceType":"datasetVersion","datasetId":5626665}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom xgboost import XGBClassifier\nimport optuna\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import roc_auc_score\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\nimport pickle\nimport cupy as cp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T02:38:06.578037Z","iopub.execute_input":"2025-08-09T02:38:06.578794Z","iopub.status.idle":"2025-08-09T02:38:08.658213Z","shell.execute_reply.started":"2025-08-09T02:38:06.578761Z","shell.execute_reply":"2025-08-09T02:38:08.657480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/playground-series-s5e8/train.csv')\nfinal = pd.read_csv('/kaggle/input/playground-series-s5e8/test.csv')\noriginal = pd.read_csv('/kaggle/input/bank-marketing-dataset-full/bank-full.csv', sep=';')\n\noriginal['y'] = original['y'].map({'no': 0, 'yes': 1})\n\ndef simplify_contact(x):\n    if x == 'unknown':\n        return 'unknown'\n    else:\n        return 'known_contact'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T02:38:09.923493Z","iopub.execute_input":"2025-08-09T02:38:09.923923Z","iopub.status.idle":"2025-08-09T02:38:13.047254Z","shell.execute_reply.started":"2025-08-09T02:38:09.923887Z","shell.execute_reply":"2025-08-09T02:38:13.046565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocessing(df):\n\n    df['job_edu'] = df['job'].astype(str) + \"_\" + df['education'].astype(str)\n    df = pd.get_dummies(df, columns=['job_edu'], prefix='job_edu')\n    df.drop('job', axis=1, inplace=True)\n    df.drop('education', axis=1, inplace=True)\n\n    df['balance_log'] = np.log1p(df['balance'].clip(lower=0))\n    \n    df = pd.get_dummies(df, columns=['marital'], prefix='marital')\n    df['default'] = df['default'].map({'yes': 1, 'no': 0})\n    df['housing'] = df['housing'].map({'yes': 1, 'no': 0})\n    df['loan'] = df['loan'].map({'yes': 1, 'no': 0})\n\n    df['contact_simple'] = df['contact'].apply(simplify_contact)\n    df = pd.get_dummies(df, columns=['contact_simple'], prefix='contact')\n    df.drop('contact', axis=1, inplace=True)\n\n    df['age^2'] = df[\"age\"]**2\n    \n    df['prev_camp'] = (df['pdays'] != -1).astype(int)\n    df['pdays'] = df['pdays'].replace(-1, 999)\n    df = pd.get_dummies(df, columns=['poutcome'], prefix='poutcome') # has unknown. but means still ongoing \n\n    df['duration_sin'] = np.sin(2*np.pi * df['duration'] / 400)\n    df['duration_cos'] = np.cos(2*np.pi * df['duration'] / 400)\n\n    month_map = {\n    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4,\n    'may': 5, 'jun': 6, 'jul': 7, 'aug': 8,\n    'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n    }\n    df['month_num'] = df['month'].map(month_map).astype('int')\n\n    df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n    df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n\n    df.drop('month_num',axis=1,inplace=True)\n\n    df = pd.get_dummies(df, columns=['month'], prefix='month')\n\n    df = pd.get_dummies(df, columns=['unknown_score_freq'], prefix='unknown_score_freq')\n    df = pd.get_dummies(df, columns=['many_no_score_freq'], prefix='many_no_score_freq')\n    \n    df['balance_per_age'] = df['balance'] / df['age']\n    df['duration_per_campaign'] = df['duration'] / (df['campaign'] + 1)\n\n    return df\n\ndef FE(X, test, c, original, target='y'):\n    new_col = f\"{c}_mean_target_orig\"\n    \n    target_map = original.groupby(c)[target].mean()\n    mapping_count = original[c].value_counts()\n    \n    global_mean = original[target].mean()\n    \n    X[f\"{c}_count\"] = X[c].map(mapping_count).fillna(0)\n    test[f\"{c}_count\"] = test[c].map(mapping_count).fillna(0)\n    \n    X[new_col] = X[c].map(target_map).fillna(global_mean)\n    test[new_col] = test[c].map(target_map).fillna(global_mean)\n    \n    return X, test\n\ndef extra(train, test):\n    combined = pd.concat([train, test], axis=0, ignore_index=True)\n    \n    def f1(x):\n        if x['education']=='unknown' and x['contact']=='unknown' and x['poutcome']=='unknown':\n            return 21\n        if (x['education']=='unknown' and x['contact']=='unknown') \\\n           or (x['education']=='unknown' and x['poutcome']=='unknown') \\\n           or (x['contact']=='unknown' and x['poutcome']=='unknown'):\n            return 7\n        if x['education']=='unknown' or x['contact']=='unknown' or x['poutcome']=='unknown':\n            return 3\n        return 0\n    \n    def f2(x):\n        if x['default']=='no' and x['housing']=='no' and x['loan']=='no':\n            return 21\n        if (x['default']=='no' and x['housing']=='no') \\\n           or (x['default']=='no' and x['loan']=='no') \\\n           or (x['housing']=='no' and x['loan']=='no'):\n            return 7\n        if x['default']=='no' or x['housing']=='no' or x['loan']=='no':\n            return 3\n        return 0\n    \n    combined['unknown_score'] = combined.apply(f1, axis=1)\n    combined['many_no_score'] = combined.apply(f2, axis=1)\n    \n    unknown_freq = combined['unknown_score'].value_counts().to_dict()\n    many_no_freq = combined['many_no_score'].value_counts().to_dict()\n    \n    combined['unknown_score_freq'] = combined['unknown_score'].map(unknown_freq)\n    combined['many_no_score_freq'] = combined['many_no_score'].map(many_no_freq)\n    \n    train_len = len(train)\n    train['unknown_score_freq'] = combined.loc[:train_len-1, 'unknown_score_freq'].values\n    test['unknown_score_freq'] = combined.loc[train_len:, 'unknown_score_freq'].values\n    \n    train['many_no_score_freq'] = combined.loc[:train_len-1, 'many_no_score_freq'].values\n    test['many_no_score_freq'] = combined.loc[train_len:, 'many_no_score_freq'].values\n    \n    return train, test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T02:38:14.177204Z","iopub.execute_input":"2025-08-09T02:38:14.177651Z","iopub.status.idle":"2025-08-09T02:38:14.192269Z","shell.execute_reply.started":"2025-08-09T02:38:14.177624Z","shell.execute_reply":"2025-08-09T02:38:14.191536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"COLS = ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n       'previous', 'poutcome',]\n\ndf.drop('id', axis=1, inplace=True)\nfinal_id = final['id']\nfinal.drop('id', axis=1, inplace=True)\n\nfor c in COLS:\n    df, test = FE(df, final, c, original)\n\ndf, final = extra(df, final)\n\ndf = preprocessing(df)\nfinal = preprocessing(final)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T02:38:18.232669Z","iopub.execute_input":"2025-08-09T02:38:18.232930Z","iopub.status.idle":"2025-08-09T02:38:52.558968Z","shell.execute_reply.started":"2025-08-09T02:38:18.232909Z","shell.execute_reply":"2025-08-09T02:38:52.558377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = df['y']\nX = df.drop('y', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T02:38:52.695563Z","iopub.execute_input":"2025-08-09T02:38:52.695842Z","iopub.status.idle":"2025-08-09T02:38:52.830116Z","shell.execute_reply.started":"2025-08-09T02:38:52.695815Z","shell.execute_reply":"2025-08-09T02:38:52.829269Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb1 = XGBClassifier(\n    colsample_bytree=0.8,\n    learning_rate=0.1,\n    max_depth=7,\n    n_estimators=200,\n    eval_metric='logloss',\n    random_state=42,\n)\n\nxgb1.fit(X, y)\n\nimportances = xgb1.feature_importances_\nfeature_ranking = np.argsort(importances)[::-1]\nsorted_features = X.columns[feature_ranking]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def objective_xgb(trial):\n\n    n_top_features = trial.suggest_int(\"top_n_features\", 70, 120)\n    selected = sorted_features[:n_top_features]\n    X_sel = X[selected]\n\n    param = {\n        'n_estimators': trial.suggest_int('n_estimators', 1200, 2000),\n        'learning_rate': trial.suggest_float('learning_rate', 0.03, 0.1),\n        'max_depth': trial.suggest_int('max_depth', 5, 10),\n        'subsample': trial.suggest_float('subsample', 0.8, 1.0),\n        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.8, 1.0),\n        'gamma': trial.suggest_float('gamma', 0.0, 0.5),\n        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 2.0),\n        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 2.0),\n        'objective': 'binary:logistic',\n        'eval_metric': 'auc',\n        'verbosity': 1,\n        'n_jobs': 1,\n        'device': 'cuda',\n        'tree_method': 'hist',\n    }\n\n    aucs = []\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n    for train_idx, val_idx in skf.split(X_sel, y):\n        X_train, X_val = X_sel.iloc[train_idx], X_sel.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n    \n        model = XGBClassifier(**param)\n        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n        preds = model.predict_proba(X_val)[:, 1]\n        aucs.append(roc_auc_score(y_val, preds))\n    return np.mean(aucs)\n\npruner = optuna.pruners.MedianPruner(n_warmup_steps=1)\nstudy_xgb = optuna.create_study(direction='maximize', pruner=pruner)\nstudy_xgb.optimize(objective_xgb, timeout=60*60*8)\n\nbest_params_xgb = study_xgb.best_params\nbest_n_features = best_params_xgb.pop(\"top_n_features\")\nbest_params_xgb.update({\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'verbosity': 1,\n    'n_jobs': 1,\n    'device': 'cuda',\n    'tree_method': 'hist',\n})\n\nselected_features = sorted_features[:best_n_features]\n\nX_sel = X[selected_features]\nfinal_sel = final[selected_features]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"xgb = XGBClassifier(**best_params_xgb)\n\nxgb.fit(X_sel, y)\n\ny_test_proba = xgb.predict_proba(final_sel)[:, 1]","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"xgb_model.pkl\", \"wb\") as f:\n    pickle.dump((xgb, selected_features), f)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"id\": final_id,\n    \"y\": y_test_proba\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{},"outputs":[],"execution_count":null}]}